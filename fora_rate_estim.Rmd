---
title: "estimate foraging rate"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages, message=FALSE}
library(here)
library(tidyverse)
library(deSolve)
library(magrittr)
library(bbmle)
```


The purpose of this document is to estimate foraging rate using maximum likelihood estimation and multiple models for foraging rate. At its simplest, foraging rate is a constant unaffected by any external conditions. However, we hypothesize that temperature and resource concentration will influence foraging rate. Under different resource conditions, we expect foraging rate to change with changes in resource concentration as a type II functional response. Under a type II functional response, foraging rate increases non-linearly with resource concentration and will asymptote at a sufficiently high resource concentration. Mechanistically, this is due to the inclusion of handling time. At a certain point, feeding rate is constrained by handling time, even if there is a seemingly endless amount of food available. Temperature is also expected to change foraging rate behavior. Temperature may increase encounter rates with food and cause the consumer to forage at a higher rate. We attempt to incorporate the effects of temperature using an Arrhenius equation, an equation typically used to model temperature affects on reaction rates. 

Overall, we will develop four models that can be used to describe foraging rate. Our independent model assumes no affects of temperature or resource conditions. Our resource-dependent model assumes a type II functional response. Our temperature-dependent model incorporates an affect of temperature using an Arrhenius equation. Our full model incoporates effects of both resource and temperature.

We will use each of these models to develop parameter estimates for foraging rate. Each model is an equation and can be used to generate data. We generate data for a range of parameter estimates and measure the likelihood of these simulated data given our actual observed data. We choose the parameter estimate under each model that maximizes the likelihood. We choose the model with the highest likelihood. 


# Model 1 - Independent model

Model 1 will also serve as an example for the more detailed methods used.

First, we can write out our equations. To do this, we should think about our experiment. In our foraging rate assay, we measured the change in resource (algae) concentration in a tube over time after adding a single daphnia to the tube. So we can write an equation to model the change in resource concentration over time.

We use a first-order linear differential equation to represent resource concentration because we expect the rate of change to depend on the amount of resources available. Normally, the rate of change of the resource (our state variable) might also include an expression for growth (usually logistic), but because we conducted this experiment in the dark we can assume that no growth is occurring and can omit omit that expression. We are left with just the loss term (how much is being foraged). Our loss term should also be a per-capita term and depend on the number of individuals foraging, but in our experiment there is only a single daphnia ever foraging per assay.
$$
\begin{equation}
f(R) = R + \frac{dR}{dt} \\
\frac{dR}{dt} = -fRS \\
\frac{dR}{dt} = -fR \\
\end{equation}
$$

Foraging rate is also expected to depend on the size of the individual. We incorporate length as a factor with a power coefficient. We can attempt to fit gamma or just assume a reasonable value. In other papers, a power coefficient of 2 is used. The idea here (I think) is that the surface area of the daphnia is what is relevant for foraging. Squaring the length gives us the surface area of a square which is close enough to the surface area of a daphnia?

$$
\frac{dR}{dt} = -L^{\gamma} fR \\
$$

Now that we have our full equation, we can use this to estimate the amount of algae after a given amount of time. We can do this by numerically solving our differential equation and seeing how much algae remains after a given amount of time. We can also solve the differential equation by writing a function that represents the change of algae over time. We'll do both of these here.

```{r, m1_num_sol}
m1_num_sol <- function(t, x, params){
  R <- x[1]
  with(as.list(params),{
    dR <- -length^gamma*f*R
    res <- c(dR)
    list(res)}
    )
}

maxTime <- 8
times <- seq(0,maxTime,by=0.1)

params <- c(f=0.5,
            length=1,
            gamma=2)

xstart <- c(R=1)

output <- as.data.frame(lsoda(xstart, times, m1_num_sol, params))

r_end <- slice_max(output, time)[,2]
```

We can use this chunk of code to get the solution for our model given any set of starting conditions and parameter values. Using our data, we can determine what set of parameter values will allow the model to best fit our data. In our data, have information about each daphnia (i.e. length) and how much they foraged over a certain amount of time.


We have the raw data so we will have to do a little bit of housekeeping before we can actually use these data.


```{r, real data}
data <- readRDS(here("processed_data","foraging_raw.rds"))

data %<>% mutate(mm = as.numeric(length)*17.86/1000) #convert length measurement into mm

data %<>% mutate(amt_consumed = resource - amt_rem)

data %<>% mutate(treatment_ID = paste(temp, resource, sep = "_"))

treatment_IDs <- unique(data$treatment_ID)
```


Using the data, we can go ahead and try out estimating f.

pseudocode:
write a loop that goes through each treatment. For each treatment, set the conditions of the solver (i.e. resource concentration; in future cases, this will also include temperature). Before we do this, we may need to write a function that will pop out the negative log-likelihood. To do this, we will need to use the solver to give us the endpoint resource concentration given a certain foraging rate. We use a function like dnorm() to calculate the likelihood of of observing data, given a certain probability. In this case, the probability is set from the result from the solver. Together, the result from the solver and the data are used to give us the likelihood and simple maths turns the likelihood into the negative log-likelihood (i.e. taking the log of the likelihood and making it negative). The optimizer (mle2() is what we sill use) takes this likelihood function and then moves through parameter space to find the parameter value that minimizes the sum of the negative log-likelihood of all the data. 

One issue with this right now is that I need a single parameter for all treatments. As written, that will give me different parameter estimates for each treatment. I think I just need to write a loop within the optimizer instead of outside it.

Okay I need to decide if I am going to do this line by line and both re-solve the ode for each since each individual technically has different length and different time of foraging. Or I can average things.

We'll use the solver for each observation for now.

```{r, m1_ll}
m1_ll <- function(f){
  resid_df <- tibble(resid=0, data$ID)
    for (i in 1:nrow(data)) {
    maxTime <- data$time[i]
    times <- seq(0, maxTime, by=0.1)
    params <- c(f=f,
                length=data$mm[i],
                gamma=2)
    xstart <- c(R=data$resource[i])
    output <- as.data.frame(lsoda(xstart, times, m1_num_sol, params, hmax = 0.1))
    
    r_end <- slice_max(output, time)[,2]
      
    resid_df$resid[i] <- r_end - data$amt_rem[i]
    }
  
    nll <- dnorm(resid_df$resid, mean = 0, sd = sd(resid_df$resid, na.rm = T), log = T)
    -sum(nll, na.rm = T)
}
```

<!-- ```{r, m1_ll} -->
<!-- m1_ll <- function(f){ -->
<!--   resid_df <- tibble(resid=0, treatment_IDs) -->
<!--     for (i in 1:length(treatment_IDs)) { -->
<!--     sub_data <- data %>% filter(treatment_ID %in% treatment_IDs[i]) -->
<!--     maxTime <- round(mean(sub_data$time, na.rm=T),2) -->
<!--     length <- mean(sub_data$mm, na.rm=T) -->
<!--     times <- seq(0, maxTime, by=0.1) -->
<!--     params <- c(f=f, -->
<!--                 length=length, -->
<!--                 gamma=2) -->
<!--     xstart <- c(R=mean(sub_data$resource, na.rm=T)) -->
<!--     output <- as.data.frame(lsoda(xstart, times, m1_num_sol, params)) -->

<!--     r_end <- slice_max(output, time)[,2] -->

<!--     resids <- r_end - sub_data$amt_rem -->

<!--     resid_df$resid[i] <- -sum(dnorm(resids, mean = 0, sd = sd(resids, na.rm = T), log = T)) -->
<!--     } -->

<!--     sum(resid_df$resid) -->
<!-- } -->
<!-- ``` -->

One issue here is that I haven't set a limit on the resource value to account for the negative feeding rate values (i.e. when fluorescence increased). I have to figure out how to do this. We'll come back to this later.

Now it is time to use the optimizer
```{r, m1_mle}

# m1_f_fit <- mle(m1_ll,
#                 start=list(f=30),
#                 method = "Brent",
#                 lower = 0,
#                 upper = 100)
start_time <- Sys.time()
m1_f_fit <- mle2(m1_ll,
                start=list(f=30),
                method = "Brent",
                lower = 0,
                upper = 100)
end_time <- Sys.time()
m1_runtime <- end_time - start_time
as.numeric(m1_runtime)
#opt1 <- optim(fn=m1_ll, par=c(30), method = "Brent", lower = 0, upper = 100) #this should be the same as mle2() since mle2() is a wrapper for optim()
```

I can get mle2() and optim() to work but not mle(). I'm not sure why right now, but I guess we can move forward.



# Model 2 - Temperature-dependent model


Next, let's try to incorporate temperature.

$$
\frac{dR}{dt} = -L^{\gamma}fe^{T_{A}(1/T_{R}-1/T)} R  \\
$$


```{r, m2_num_sol}
m2_num_sol <- function(t, x, params){
  R <- x[1]
  with(as.list(params),{
    dR <- -(length^gamma)*f*exp(arr_t*(1/ref_t - 1/temp))*R
    res <- c(dR)
    list(res)}
    )
}

maxTime <- 8
times <- seq(0,maxTime,by=0.1)

params <- c(f=0.5,
            length=1,
            gamma=2,
            arr_t=1.5,
            ref_t=20,
            temp=25)

xstart <- c(R=1)

output <- as.data.frame(lsoda(xstart, times, m2_num_sol, params))

r_end <- slice_max(output, time)[,2]
```


```{r, m2_ll}
m2_ll <- function(f){
  resid_df <- tibble(resid=0, data$ID)
    for (i in 1:nrow(data)) {
    maxTime <- data$time[i]
    times <- seq(0, maxTime, by=0.1)
    params <- c(f=f,
                length=data$mm[i],
                gamma=2,
                arr_t=1.5,
                ref_t=20,
                temp=data$temp[i])
    xstart <- c(R=data$resource[i])
    output <- as.data.frame(lsoda(xstart, times, m2_num_sol, params, hmax = 0.1))
    
    r_end <- slice_max(output, time)[,2]
      
    resid_df$resid[i] <- r_end - data$amt_rem[i]
    }
  
    nll <- dnorm(resid_df$resid, mean = 0, sd = sd(resid_df$resid, na.rm = T), log = T)
    -sum(nll, na.rm = T)
}
```



```{r, m2_mle}
start_time <- Sys.time()
m2_f_fit <- mle2(m2_ll,
                start=list(f=30),
                method = "Brent",
                lower = 0,
                upper = 100)
end_time <- Sys.time()
m2_runtime <- end_time - start_time
as.numeric(m2_runtime)
```


# Resource-dependent model


$$
\frac{dR}{dt} = -L^{\gamma} \frac{fR}{1 + fhR} \\
$$

```{r, m3_num_sol}
m3_num_sol <- function(t, x, params){
  R <- x[1]
  with(as.list(params),{
    dR <- -length^gamma*((f*R)/(1+f*h*R))
    res <- c(dR)
    list(res)}
    )
}

maxTime <- 8
times <- seq(0,maxTime,by=0.1)

params <- c(f=0.5,
            length=1,
            gamma=2,
            h=1)

xstart <- c(R=1)

output <- as.data.frame(lsoda(xstart, times, m3_num_sol, params))

r_end <- slice_max(output, time)[,2]
```


```{r, m3_ll}
m3_ll <- function(f){
  resid_df <- tibble(resid=0, data$ID)
    for (i in 1:nrow(data)) {
    maxTime <- data$time[i]
    times <- seq(0, maxTime, by=0.1)
    params <- c(f=f,
                length=data$mm[i],
                gamma=2,
                h=1)
    xstart <- c(R=data$resource[i])
    output <- as.data.frame(lsoda(xstart, times, m3_num_sol, params, hmax = 0.1))
    
    r_end <- slice_max(output, time)[,2]
      
    resid_df$resid[i] <- r_end - data$amt_rem[i]
    }
  
    nll <- dnorm(resid_df$resid, mean = 0, sd = sd(resid_df$resid, na.rm = T), log = T)
    -sum(nll, na.rm = T)
}
```


```{r, m3_mle}
start_time <- Sys.time()
m3_f_fit <- mle2(m3_ll,
                start=list(f=30),
                method = "Brent",
                lower = 0,
                upper = 100)
end_time <- Sys.time()
m3_runtime <- end_time-start_time
as.numeric(m3_runtime)
```


# Temperature and resource-dependent model


$$
\frac{dR}{dt} = -L^{\gamma}\frac{fe^{T_{A}(1/T_{R}-1/T)} R}{1 + fe^{T_{A}(1/T_{R}-1/T)}hR}  \\
$$


```{r, m4_num_sol}
m4_num_sol <- function(t, x, params){
  R <- x[1]
  with(as.list(params),{
    dR <- -(length^gamma)*((f*exp(arr_t*(1/ref_t - 1/temp))*R)/(1+f*exp(arr_t*(1/ref_t - 1/temp))*h*R))
    res <- c(dR)
    list(res)}
    )
}

maxTime <- 8
times <- seq(0,maxTime,by=0.1)

params <- c(f=0.5,
            length=1,
            gamma=2,
            arr_t=1.5,
            ref_t=20,
            h=1,
            temp=25)

xstart <- c(R=1)

output <- as.data.frame(lsoda(xstart, times, m4_num_sol, params))

r_end <- slice_max(output, time)[,2]
```


```{r, m4_ll}
m4_ll <- function(f){
  resid_df <- tibble(resid=0, data$ID)
    for (i in 1:nrow(data)) {
    maxTime <- data$time[i]
    times <- seq(0, maxTime, by=0.1)
    params <- c(f=f,
                length=data$mm[i],
                gamma=2,
                arr_t=1.5,
                ref_t=20,
                temp=data$temp[i],
                h=1)
    xstart <- c(R=data$resource[i])
    output <- as.data.frame(lsoda(xstart, times, m4_num_sol, params, hmax = 0.1))
    
    r_end <- slice_max(output, time)[,2]
      
    resid_df$resid[i] <- r_end - data$amt_rem[i]
    }
  
    nll <- dnorm(resid_df$resid, mean = 0, sd = sd(resid_df$resid, na.rm = T), log = T)
    -sum(nll, na.rm = T)
}
```

```{r, m4_mle}
start_time <- Sys.time()
m4_f_fit <- mle2(m4_ll,
                start=list(f=30),
                method = "Brent",
                lower = 0,
                upper = 100)
end_time <- Sys.time()
m4_runtime <- end_time-start_time
as.numeric(m4_runtime)
```

