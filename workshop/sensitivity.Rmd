---
title: "sensitivity"
author: "Daniel Suh"
date: "`r Sys.Date()`"
output: html_document
---

```{r, message=F}
library(here)

source(here("base","src.R"))
```

Let's try a global sensitivity analysis using latin hypercube sampling and partial rank correlation coefficients.

To start, I need to sample from a range of parameter values. We do this using latin hypercube sampling (LHS). After assuming some sort of probability density function for each parameter, LHS divides these evenly and samples from each division. These values are then used as parameters for the model and a model output can be obtained. We do this N number of times and generate a lot of different outputs for all of our inputs (we use matrices to keep this all organized). Using the model outputs, we can then create scatter plots of outputs (y-axis) relative to the parameter of interest (x-axis). If the relationship is non-linear and monotonic, then Partial Rank Correlation Coefficients can be used. If the relationship is non-linear and non-monotonic, then another method should be used (efAST). For now, we are hoping that we can use PRCC. PRCC's are calculated and can be used to estimated sensitivity of an output for a given input (parameter) and these PRCC's can be tested for significant differences from each other or from 0.

This is a useful paper for understanding these methods: <https://doi.org/10.1016/j.jtbi.2008.04.011> And this is their website with code for implementation: <http://malthus.micro.med.umich.edu/lab/usanalysis.html>

One question is how to assess sensitivity of an output of interest (e.g. R0) for different environmental conditions. We can say which parameter R0 is most sensitive to under different temperature and resource conditions, but can we say whether R0 is more sensitive to changes in temperature or resource conditions? I guess I'm not even sure how we would relativize that since temperature and resources are on completely different scales.

Another thing. Can I get the probability density function from the boostrapped confidence intervals for the parameter estimates? And then can I base the range and pdf shape from that?

I guess first thing to do is to define the model

Simplified model from Strauss et al. 2018 ecol letters. Resource density modeled as a constant rather than a variable. Multiple parameters summarized (birth rate, susceptible and infected death rate, transmission rate)

![Daphnia-Metschnikowia](/Users/dcsuh/Documents/GitHub/temp_rsc_zoops/papers/daphnia_model.png)

```{r}
daphnia <- function(t, x, params){

  # states
  S <- x[1]
  I <- x[2]
  Z <- x[3]
  N <- S+I
  
  # calculated parameters
  susc <- params$beta/params$fora
  
  # rates
  r1 <- params$birth*N # susceptible births
  r2 <- params$death*S # susceptible deaths
  r3 <- susc*params$fora*Z*S # transmission
  r4 <- params$death*I # infected deaths
  r5 <- params$yield # per individual yield
  r6 <- params$fora*Z*N # spore removal
  r7 <- params$loss*Z # spore degradation

  # derivatives
  dS <- r1 - r2 - r3
  dI <- r3 - r4
  dZ <- r5*r4 - r6 - r7
    
  #output
  out <- list(c(dS, dI, dZ))
}

```

```{r}
times <- seq(0, 60, by=0.1)  #solve for 
params <- list(birth=0.25, # birth rate; births per day
               fora=0.0029898716*1.44, # foraging rate; liters per day
               death=0.01, # death rate
               beta=0.000002209164, # transmission rate
               yield=55496.324, # spore yield
               loss=0.02) # spore loss
pop.size <- 1
Z0 <- 200000
xstart <- c(S=pop.size, I=0 , Z=Z0)
out <- as.data.frame(ode(xstart, times, daphnia, params))
```

```{r}
out %>% ggplot(.,aes(x=time))+
  geom_line(aes(y=S,col="Susceptible"))+
  geom_line(aes(y=I,col="Infected"))+
  geom_line(aes(y=Z,col="Spores"))+
  scale_colour_manual(values = c("red","green","black"))+
  labs(y="N",x="Time",col="Population")
```


```{r}
h <- 1000               #choose number of points
set.seed(8878896)
lhs<-maximinLHS(h,7)   #simulate
```

```{r}
beta.summary <- readRDS(here("processed_data", "beta_summary.rds"))
lt_full <- readRDS(here("processed_data", "lt_full_summary.rds"))
spores <- readRDS(here("processed_data", "spore_yield.rds"))
foraging <- readRDS(here("processed_data", "foraging.rds"))
```

```{r}
i <- 9
j <- 6

birth_min = lt_full$S.b.U.025[i]
birth_max = lt_full$S.b.U.975[i]

fora_min = 0
fora_max = foraging$rate_mean[j] + foraging$rate_se[j]

death_min = lt_full$S.d.U.025[i]
death_max = lt_full$S.d.U.975[i]

beta_min = beta.summary$beta.025[i]
beta_max = beta.summary$beta.975[i]

susc_min = lt_full$S.S.025[i]
susc_max = lt_full$S.S.975[i]

yield_min = spores$mean_yield[i] - spores$se[i]
yield_max = spores$mean_yield[i] + spores$se[i]

loss_min = 0.2 - 0.05
loss_max = 0.2 + 0.05
```

```{r}
params.set <- as_tibble(cbind(
  birth = lhs[,1]*(birth_max - birth_min) + birth_min,
  fora = lhs[,2]*(fora_max - fora_min) + fora_min,
  death = lhs[,3]*(death_max - death_min) + death_min,
  beta = lhs[,4]*(beta_max - beta_min) + beta_min,
  susc = lhs[,5]*(susc_max - susc_min) + susc_min,
  yield = lhs[,6]*(yield_max - yield_min) + yield_min,
  loss = lhs[,7]*(loss_max - loss_min) + loss_min
))
```

For now, we don't even need to simulate model dynamics to get sensitivity of R0 for multiple params. I can just plug in the analytical version of R0 which is:

$$ 
R\emptyset = \frac { \beta S^* \sigma }{ \mu } \\

\beta = transmission\ rate \\

S^*= equilibrium\ susceptible\ host\ density \\

\sigma = spore\ yield \\

\mu = degradation\ rate \\ 
$$

Also, to start, we will just do the sensitivity analysis for a single set of conditions. 15 Degrees at high food. Afterwards, I can rewrite this as a loop so that I can loop through all conditions.


```{r}
data <- tibble(params.set, R0 = NA)
data %<>% na_if(., .)
```



```{r}
for(k in 1:h){
  data[k,1:7] <- params <- as.list(c(params.set[k,]))
  tmp <- (params.set$beta[k]*params.set$susc[k]*params.set$yield[k])/params.set$loss[k] #calculate R0
  data[k, 8] <- tmp
}
```




