---
title: "foraging"
author: "Daniel Suh"
date: "`r Sys.Date()`"
output: html_document
---

```{r, message = F}
library(here)
source(here("base","src.R"))
```

```{r}
data <- read_csv(here("raw_data","foraging.csv"))
```
Effects of temperature and resources on prevalence
![prevalence](figures/prob_inf.png)


```{r}
data %<>% mutate(length = as.numeric(length),
                 start_min = time_in_hr*60+time_in_min,
                 end_min = time_measured_hr*60+time_measured_min,
                 time = end_min-start_min,
                 vol = 15)

control <- data %>% filter(trt=="C") %>% group_by(temp, resource, block) %>% summarize(control_read = mean(read, na.rm=T))

data %<>% left_join(., control)
```

```{r}
#this calculation comes from Hite et al. 2020 and assumes a strong linear relationship between fluorescence and algae conc
data %<>% filter(trt=="trt") %>% mutate(rate = log(control_read/read)*(vol/time), #vol is mL and time is min for a rate of mL/min
                                        amt_rem = ((resource/control_read)*read), #final resource concentration
                                        amt_rem_tot = ((resource*vol/control_read)*read)) #final resource amount


data_summ <- data %>% group_by(temp, resource) %>% summarize(rate_mean = mean(rate),
                                                             rate_var = var(rate),
                                                             rate_sd = sd(rate),
                                                             rate_se = sd(rate)/sqrt(n()),
                                                             amt_mean = mean(amt_rem_tot),
                                                             amt_var = var(amt_rem_tot),
                                                             amt_sd = sd(amt_rem_tot),
                                                             amt_se = sd(amt_rem_tot)/sqrt(n()),
                                                             length_mean = mean(length, na.rm = T),
                                                             length_var = var(length, na.rm = T),
                                                             length_sd = sd(length, na.rm = T),
                                                             length_se = sd(length, na.rm = T)/sqrt(n()),
                                                             time_mean = mean(time, na.rm = T))

# data_summ <- data %>% group_by(temp, resource, block) %>% summarize(mean_rate = mean(rate),
#                                                              var = var(rate),
#                                                              sd = sd(rate),
#                                                              se = sd(rate)/sqrt(n()))
# 
# data_summ1 %<>% mutate(block = NA)
# 
# data_summ %<>% rbind(., data_summ1)

# data_summ %<>% mutate(ID = paste(temp,resource, sep = "_"),
#                       block_ID = paste(temp, resource, block, sep = "_"))


data_summ %<>% mutate(species = "D",
                      ID = paste(temp,resource, sep = "_"))

saveRDS(data, file = here("processed_data", "foraging_raw.rds"))
saveRDS(data_summ, file = here("processed_data", "foraging.rds"))

```


```{r}
data_summ %>% 
#  filter(is.na(block)) %>% 
  ggplot(aes(x=ID, y=rate_mean)) + 
  geom_point() + 
  geom_linerange(aes(ymin=rate_mean-rate_se, ymax=rate_mean+rate_se)) + 
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1)) + 
  labs(y = "mL/minute",
       x = "treatment")
```

```{r}
data_summ %>% 
#  filter(is.na(block)) %>% 
  ggplot(aes(x=as.factor(resource), y=rate_mean, group = temp, color = as.factor(temp))) + 
  geom_point(position = position_dodge(width = 0.5)) + 
  geom_linerange(aes(ymin=rate_mean-rate_se, ymax=rate_mean+rate_se),position = position_dodge(width = 0.5)) + 
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1)) + 
  scale_color_manual(values = c("#619CFF", "#00BA38", "#F8766D")) +
  labs(y = "mL/minute",
       x = "Resource",
       color = "Temp")
```

![prevalence](figures/prob_inf.png)


```{r}
data_summ %>% ggplot(aes(x=ID, y=amt_mean)) + 
  geom_point() + 
  geom_linerange(aes(ymin=amt_mean-amt_se, ymax=amt_mean+amt_se)) + 
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1)) + 
  labs(y = "amount remaining",
       x = "treatment")
```

```{r}
data_summ %>% ggplot(aes(x=as.factor(resource), y=amt_mean, group = temp, color = as.factor(temp))) + 
  geom_point(position = position_dodge(width = 0.5)) + 
  geom_linerange(aes(ymin=amt_mean-amt_se, ymax=amt_mean+amt_se),position = position_dodge(width = 0.5)) + 
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1)) + 
  scale_color_manual(values = c("#619CFF", "#00BA38", "#F8766D")) +
  labs(y = "fluor diff/time (min)",
       x = "Resource",
       color = "Temp")
```

```{r}
data_summ %>% ggplot(.,aes(x=length_mean, y=rate_mean, color = as.factor(temp), shape = as.factor(resource))) + 
  geom_point(aes(),size = 3) +
  geom_errorbarh(aes(xmin = length_mean-length_se, xmax = length_mean+length_se)) +
  geom_errorbar(aes(ymin = rate_mean-rate_se, ymax = rate_mean+rate_se)) +
  scale_color_manual(values = c("#619CFF", "#00BA38", "#F8766D")) +
  labs(x = "Average Length (raw)", y = "feeding rate (mL/min)", color = "Temp", shape = "Resource")

```


Given the raw data, what is the relationship between resource concentration and feeding rate at a given temperature? What function best fits the data?

Start with plotting raw data for feeding rate given resource concentration at each temperature

```{r}
data %>% ggplot(., aes(x = resource, y = rate)) + geom_point() + facet_wrap(vars(temp))
```

Foraging rate increases with temperature
Foraging rate decreases with increasing resource concentration. The greater the resource concentration, the less foraging is required to meet a minimum amount of resource foraged.

How do we fit a function to these data at each given temperature?
Four steps:
 - define a function to describe our model
 - define a function to calculate negative log-likelihood
    what is a negative log-likelihood function? this is a function that will generate the negative log-likelihood given a certain parameter value.
    what is negative log-likelihood? negative log-likelihood is one way of measuring the likelihood of observing a full dataset and is obtained by summing all of the negative log-likelihoods for each observed data point
 - use function to perform non-linear search for best parameter values
 
What are we trying to do here?
We have data that are generated from a biological process. In this case, we have the foraging rate data for daphnia under different temperature and resource conditions. We can write a model that represents this process. In our case, functional feeding responses are a set of models that already attempt to do exactly this. Given a gradient of resource concentrations, they attempt to describe how this relates to the amount of a resource an organism consumes in a given amount of time. After defining our model, we can compare model results to the data that we actually have to determine how likely it is that our model could generate those data. If we do this for many different parameter estimates, then we can compare these outputs to determine which set of parameters are most likely to generate the data that we observed. We can then make reasonable statements about the process that could have generated these data and compare the likelihood that different models and parameter estimates could ahve generated these data. 
 
define functions
functional feeding response II
```{r}
#x = attack rate
#y = resource concentration
#z = handling time
feed_2 <- function(x, y, z) {
  mu <- (x*y)/(1 + x*y*z)
  return(mu)
}

x <- 0.5

z <- 1

dat2 <- tibble(y = runif(100, 0, 10),
            x = x,
            z = z)

dat2 %<>% mutate(mu = (x*y)/(1 + x*y*z))
```
 



functional feeding response III
```{r}
#x = attack rate
#y = resource concentration
#z = handling time
#k = encounters
feed_3 <- function(x, y, z, k) {
  mu <- (x*y^k)/(1 + x*z*y^k)
  return(mu)
}

x <- 0.5

z <- 1

k <- 4

dat3 <- tibble(y = runif(100, 0, 10),
            x = x,
            z = z,
            k = k)

dat3 %<>% mutate(mu = (x*y^k)/(1 + x*z*y^k))
```
 

```{r}
dat2 %>% ggplot(.,aes(x=y, y=mu)) + geom_point() + labs(title = "feeding response II")

dat3 %>% ggplot(.,aes(x=y, y=mu)) + geom_point() + labs(title = "feeding response III")
```

```{r}
tmp = data$amt_time
```


dnorm calculates the normal likelihood for a data set. log is set to "T" to get the log-likelihood. the wrapper -sum() measures the sum of the negative log-likelihood for all of the observed data. The defined negative log-likelihood function that we wrote 


functional response II function for negative log-likelihood
```{r}
LL2 <- function(y, data = tmp) {
  mu <- (0.5*y)/(1 + 0.5*y*1)
  return(-sum(dnorm(data, mu, log=T)))
}
```

functional response III function for negative log-likelihood
```{r}
LL3 <- function(x, y, z, k, data) {
  mu <- (x*y^k)/(1 + x*z*y^k)
  return(-sum(dnorm(mu, data, log=T)))
}
```

```{r}
library(bbmle)
```

MLE for II
```{r}
m2 <- mle2(minuslogl = LL2, 
           start = list(y=1),
           control = list(maxit = 5000))
```



current issue:

I am not really understanding the negative log likelihood function. If I am understanding it properly, then this function should be generating a set of individual likelihoods and then summing these to get the full negative log-likelihood. I am just not sure where the actual data are being used here. I don't understand how dnorm takes both the generated data and the actual data and provides the negative log-likelihood. Unless the log-likelihood is similar to summing the error between the generated and actual data but this seems wrong.

